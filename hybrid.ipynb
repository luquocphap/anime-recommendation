{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dbb57e2",
   "metadata": {},
   "source": [
    "### Recommend Anime dựa trên hệ thống hybrid (collaborative và content-based filtering)\n",
    "    - Kết hợp kết quả dự đoán cho kết quả từ ALS đã tìm được và kết quả dự đoán từ embedding (content-based filtering)\n",
    "    - Sử dụng phương pháp lai để loại trừ khuyết điểm của các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fe0774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LU QUOC PHAP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "import metrics_eval\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import faiss\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from functools import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "306d6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rating = pd.read_csv(\"Dataset/train_rating.csv\")\n",
    "test_rating = pd.read_csv(\"Dataset/test_rating.csv\")\n",
    "embedding_anime = pd.read_csv(\"Dataset/embedding_anime.csv\")\n",
    "rating = pd.read_csv(\"Dataset/rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c0c94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item-Based: Sẵn sàng (n_items=12017)\n"
     ]
    }
   ],
   "source": [
    "# 1. Tiền xử lý text (từ item-based)\n",
    "ps = PorterStemmer()\n",
    "def stems(text: str):\n",
    "    l = list(map(ps.stem, text.split()))\n",
    "    return \" \".join(l)\n",
    "\n",
    "embedding_anime['tags'] = embedding_anime['description'].apply(stems)\n",
    "\n",
    "# 2. Vector hóa (từ item-based)\n",
    "cv = CountVectorizer(max_features=1000, stop_words='english')\n",
    "vector = cv.fit_transform(embedding_anime['tags']).toarray()\n",
    "\n",
    "# 3. Chuẩn hóa vector và tạo index FAISS (từ item-based)\n",
    "vector = vector.astype(np.float32)\n",
    "row_norm = np.linalg.norm(vector, axis=1, keepdims=True) + 1e-12\n",
    "vector = vector / row_norm\n",
    "\n",
    "item_ids = embedding_anime['anime_id'].to_numpy()\n",
    "row_of = {int(a): i for i, a in enumerate(item_ids)}\n",
    "n_items, dim = vector.shape\n",
    "\n",
    "topk_neighbors = 200  \n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(vector.astype('float32'))\n",
    "sim_all, idx_all = index.search(vector.astype('float32'), topk_neighbors + 1)\n",
    "\n",
    "nbr_idx = idx_all[:, 1:].astype(np.int32)\n",
    "nbr_sim = sim_all[:, 1:].astype(np.float32)\n",
    "\n",
    "# 4. Tạo User Likes Map (từ item-based)\n",
    "liked_threshold = 5          \n",
    "limit_liked_per_user = 30    \n",
    "rank_decay = 0.9             \n",
    "k_recommend = 20  \n",
    "\n",
    "df_likes = (train_rating[\n",
    "        (train_rating['rating'] >= liked_threshold) | (train_rating['rating'] == -1)\n",
    "    ]\n",
    "            .sort_values(['user_id', 'rating'], ascending=[True, False]))\n",
    "user_likes_map = df_likes.groupby('user_id')['anime_id'].apply(list).to_dict()\n",
    "\n",
    "item_popularity = train_rating['anime_id'].value_counts()\n",
    "cold_start_top = [int(a) for a in item_popularity.index if int(a) in row_of][:k_recommend]\n",
    "\n",
    "print(f\"Item-Based: Sẵn sàng (n_items={n_items})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bb06bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS: Sẵn sàng (Users=73515, Items=11200)\n"
     ]
    }
   ],
   "source": [
    "# 1. Ánh xạ Confidence (từ ALS)\n",
    "def confidence_mapping(r):\n",
    "    if r == -1: return 5\n",
    "    elif r >= 8: return 10\n",
    "    elif r >= 5: return 4\n",
    "    else: return 1\n",
    "\n",
    "rating['confidence'] = rating['rating'].apply(confidence_mapping)\n",
    "train_rating['confidence'] = train_rating['rating'].apply(confidence_mapping)\n",
    "test_rating['confidence'] = test_rating['rating'].apply(confidence_mapping)\n",
    "\n",
    "# 2. Tạo User/Item Maps và Ma trận (từ ALS)\n",
    "all_users = sorted(rating[\"user_id\"].unique())\n",
    "all_items = sorted(rating[\"anime_id\"].unique()) # Đây là các item trong mô hình ALS\n",
    "\n",
    "user_map = {u: i for i, u in enumerate(all_users)}\n",
    "item_map = {it: j for j, it in enumerate(all_items)}\n",
    "\n",
    "# *** PHẦN MỚI QUAN TRỌNG ***\n",
    "# Tạo map ngược từ index của ALS về anime_id\n",
    "idx_to_anime_id_map = {v: k for k, v in item_map.items()}\n",
    "\n",
    "\n",
    "train_rating[\"user_idx\"] = train_rating[\"user_id\"].map(user_map)\n",
    "train_rating[\"item_idx\"] = train_rating[\"anime_id\"].map(item_map)\n",
    "test_rating[\"user_idx\"]  = test_rating[\"user_id\"].map(user_map)\n",
    "test_rating[\"item_idx\"]  = test_rating[\"anime_id\"].map(item_map)\n",
    "\n",
    "user_items = csr_matrix(\n",
    "    (train_rating[\"confidence\"].values, (train_rating[\"user_idx\"].values, train_rating[\"item_idx\"].values)),\n",
    "    shape=(len(all_users), len(all_items)),\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "print(f\"ALS: Sẵn sàng (Users={len(all_users)}, Items={len(all_items)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10b00e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LU QUOC PHAP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: OpenBLAS is configured to use 12 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "100%|██████████| 100/100 [04:50<00:00,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS Model trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện mô hình ALS\n",
    "model = AlternatingLeastSquares(factors=150, regularization=0.1, iterations=100, random_state=42)\n",
    "model.fit(user_items)\n",
    "\n",
    "print(\"ALS Model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa8d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm chuẩn hóa điểm về [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "def normalize_scores(scores):\n",
    "    if not isinstance(scores, np.ndarray):\n",
    "        scores = np.array(scores)\n",
    "    \n",
    "    # Nếu tất cả điểm bằng nhau (ví dụ: [0, 0, 0]), scaler sẽ lỗi\n",
    "    if scores.max() == scores.min():\n",
    "        return np.zeros_like(scores)\n",
    "        \n",
    "    return scaler.fit_transform(scores.reshape(-1, 1)).flatten()\n",
    "\n",
    "# *** PHẦN ĐIỀU CHỈNH ***\n",
    "def get_item_based_scores(user_id: int,\n",
    "                            rank_decay_val: float = rank_decay,\n",
    "                            l_cap: int = limit_liked_per_user):\n",
    "    \n",
    "    liked_ids = user_likes_map.get(int(user_id), [])\n",
    "    if not liked_ids:\n",
    "        # Trả về 0 cho mọi item nếu là cold start\n",
    "        return np.zeros(n_items, dtype=np.float32)\n",
    "\n",
    "    if l_cap is not None and len(liked_ids) > l_cap:\n",
    "        liked_ids = liked_ids[:l_cap]\n",
    "\n",
    "    liked_rows = np.fromiter((row_of[a] for a in liked_ids if a in row_of), dtype=np.int32, count=-1)\n",
    "    if liked_rows.size == 0:\n",
    "        return np.zeros(n_items, dtype=np.float32)\n",
    "\n",
    "    cand_idx = nbr_idx[liked_rows]    # (L, K)\n",
    "    cand_sim = nbr_sim[liked_rows]    # (L, K)\n",
    "\n",
    "    if rank_decay_val != 1.0:\n",
    "        ranks = np.arange(cand_idx.shape[1], dtype=np.float32)  # 0..K-1\n",
    "        cand_sim = cand_sim * (rank_decay_val ** ranks)[None, :]\n",
    "\n",
    "    # cộng dồn vector hoá\n",
    "    scores = np.zeros(n_items, dtype=np.float32)\n",
    "    np.add.at(scores, cand_idx.ravel(), cand_sim.ravel())\n",
    "\n",
    "    # loại item đã xem (chúng ta sẽ làm điều này ở hàm hybrid cuối cùng)\n",
    "    # scores[liked_rows] = -np.inf \n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe25c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_hybrid(user_id, k=20, n_candidates=100, lambda_val=0.6):\n",
    "    \n",
    "    # 0. Kiểm tra Cold Start\n",
    "    if user_id not in user_map or user_id not in user_likes_map:\n",
    "        return cold_start_top[:k] # Trả về popular cho user mới\n",
    "    \n",
    "    user_idx = user_map[user_id]\n",
    "    \n",
    "    # 1. Lấy Ứng viên từ ALS\n",
    "    # (Hàm này trả về item_idx của ALS)\n",
    "    als_indices, als_scores = model.recommend(user_idx, user_items[user_idx], N=n_candidates)\n",
    "    \n",
    "    # 2. Lấy *tất cả* điểm từ Item-Based (IB)\n",
    "    # (Hàm này trả về điểm cho item_row của IB)\n",
    "    ib_scores_all = get_item_based_scores(user_id)\n",
    "    \n",
    "    # Chuẩn hóa điểm số\n",
    "    als_scores_norm = normalize_scores(als_scores)\n",
    "    # Chỉ chuẩn hóa các điểm IB của các ứng viên ALS (tránh chuẩn hóa cả 12017 item)\n",
    "    ib_candidate_scores = []\n",
    "    \n",
    "    \n",
    "    hybrid_candidates = []\n",
    "    \n",
    "    # Lấy các item người dùng đã xem để lọc\n",
    "    liked_items_set = set(user_likes_map.get(user_id, []))\n",
    "    \n",
    "    for i in range(len(als_indices)):\n",
    "        item_idx_als = als_indices[i]\n",
    "        \n",
    "        # Chuyển từ index của ALS -> anime_id\n",
    "        anime_id = idx_to_anime_id_map.get(item_idx_als)\n",
    "        \n",
    "        if anime_id is None or anime_id in liked_items_set:\n",
    "            continue\n",
    "            \n",
    "        # Chuyển từ anime_id -> index của Item-Based (row_of)\n",
    "        if anime_id not in row_of:\n",
    "            continue # Anime này có trong ALS nhưng không có trong model Item-Based\n",
    "            \n",
    "        item_row_ib = row_of[anime_id]\n",
    "        \n",
    "        # Lấy điểm\n",
    "        als_score = als_scores_norm[i]\n",
    "        ib_score = ib_scores_all[item_row_ib] # Lấy điểm IB tương ứng\n",
    "        \n",
    "        hybrid_candidates.append({\n",
    "            \"anime_id\": anime_id,\n",
    "            \"als_score_norm\": als_score,\n",
    "            \"ib_score_raw\": ib_score  # Sẽ chuẩn hóa sau\n",
    "        })\n",
    "\n",
    "    if not hybrid_candidates:\n",
    "        return cold_start_top[:k] # Không tìm thấy ứng viên nào\n",
    "        \n",
    "    # Chuẩn hóa riêng điểm IB của các ứng viên\n",
    "    ib_scores_to_norm = [c['ib_score_raw'] for c in hybrid_candidates]\n",
    "    ib_scores_norm = normalize_scores(ib_scores_to_norm)\n",
    "    \n",
    "    # 3. Tính điểm Hybrid\n",
    "    final_scores = []\n",
    "    for i, c in enumerate(hybrid_candidates):\n",
    "        ib_score = ib_scores_norm[i]\n",
    "        als_score = c['als_score_norm']\n",
    "        \n",
    "        final_score = (lambda_val * als_score) + ((1 - lambda_val) * ib_score)\n",
    "        \n",
    "        final_scores.append((c['anime_id'], final_score))\n",
    "        \n",
    "    # 4. Sắp xếp và trả về Top K\n",
    "    final_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [anime_id for anime_id, score in final_scores[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ddc8fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Đề xuất cho User 9229 ---\n",
      "['Baccano!', 'Rose of Versailles', 'Detective Conan Movie 13: The Raven Chaser', 'Mirai Shounen Conan', 'Clannad: Mou Hitotsu no Sekai, Tomoyo-hen', 'Detective Conan OVA 09: The Stranger in 10 Years...', 'Takarajima', 'Akachan to Boku', 'Clannad: After Story - Mou Hitotsu no Sekai, Kyou-hen', 'Detective Conan Movie 01: The Timed Skyscraper', 'Lupin III vs. Detective Conan', 'Watashi no Ashinaga Ojisan', 'Itazura na Kiss', 'Ai no Wakakusa Monogatari', 'Detective Conan OVA 01: Conan vs. Kid vs. Yaiba', 'Digimon Adventure 02', 'Kazoku Robinson Hyouryuuki: Fushigi na Shima no Flone', 'Alps no Shoujo Heidi', 'Digimon Frontier', 'Jungle Book Shounen Mowgli']\n"
     ]
    }
   ],
   "source": [
    "# Thử nghiệm trên một user\n",
    "test_user_id = 9229\n",
    "print(f\"--- Đề xuất cho User {test_user_id} ---\")\n",
    "\n",
    "hybrid_recs_ids = recommend_hybrid(test_user_id, k=20, lambda_val=0.7)\n",
    "\n",
    "# Lấy tên anime\n",
    "hybrid_recs_names = embedding_anime[embedding_anime['anime_id'].isin(hybrid_recs_ids)]['name']\n",
    "print(hybrid_recs_names.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "319d2d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu đánh giá trên 71102 users...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 6168 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 17688 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 33816 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 54552 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 70896 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 71079 out of 71102 | elapsed:  8.3min remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 71102 out of 71102 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Kết quả Đánh giá Mô hình Hybrid (λ=0.6) ---\n",
      "{'Precision@15': 0.2938529624108089, 'Recall@15': 0.3081397886460829, 'MAP@15': 0.27814608864763496}\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá trên toàn bộ tập Test\n",
    "\n",
    "# 1. Lấy Ground Truth (từ 2 notebook)\n",
    "ground_truth = (\n",
    "    test_rating\n",
    "    .groupby('user_id')['anime_id']\n",
    "    .apply(set)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Lọc ground_truth để chỉ giữ các user có trong ALS (để so sánh công bằng)\n",
    "all_users_test = [u for u in ground_truth.keys() if u in user_map]\n",
    "ground_truth_filtered = {u: ground_truth[u] for u in all_users_test}\n",
    "\n",
    "print(f\"Bắt đầu đánh giá trên {len(all_users_test)} users...\")\n",
    "\n",
    "# 2. Chạy dự đoán (dùng song song)\n",
    "def _predict_one_hybrid(u):\n",
    "    return int(u), recommend_hybrid(int(u), k=20, lambda_val=0.7) # Giữ lambda = 0.6\n",
    "\n",
    "# Giảm batch_size nếu bị treo/hết bộ nhớ\n",
    "predicted_list_hybrid = Parallel(n_jobs=-1, backend=\"loky\", batch_size=128, verbose=5)(\n",
    "    delayed(_predict_one_hybrid)(u) for u in all_users_test\n",
    ")\n",
    "\n",
    "predicted_hybrid = dict(predicted_list_hybrid)\n",
    "\n",
    "# 3. Tính toán Metrics\n",
    "result_hybrid = metrics_eval.evaluate_all(predicted_hybrid, ground_truth_filtered, k=15)\n",
    "\n",
    "print(\"\\n--- Kết quả Đánh giá Mô hình Hybrid (λ=0.6) ---\")\n",
    "print(result_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e736dac",
   "metadata": {},
   "source": [
    "- đã chạy (8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
